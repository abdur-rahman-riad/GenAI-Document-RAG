{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3079389b-038a-4f8b-ab46-bdbd48ea5c05",
   "metadata": {},
   "source": [
    "**Load PDF File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4cb93e9-e181-43b9-a6b0-98d3ef7c7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff3c60e2-5bf2-482e-8ac9-c9cb04c0c837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Path: Data/As a Man Thinketh.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"Data/As a Man Thinketh.pdf\"\n",
    "reader = PdfReader(pdf_path)\n",
    "\n",
    "print(\"PDF Path:\", pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4017abf-03f7-43e2-8ffc-dd34a74a06fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Characters (PyPDF): 44346\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    text += page.extract_text()\n",
    "\n",
    "print(\"Extracted Characters (PyPDF):\", len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfbd8fe-ad15-46e6-a694-9da9749fcecf",
   "metadata": {},
   "source": [
    "**OCR Engine (Tesseract)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc41af1f-bbc0-4482-8677-2eaf7d049df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to Images...\n",
      "Total Pages: 21\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting PDF to Images...\")\n",
    "images = convert_from_path(pdf_path, dpi=300)\n",
    "print(\"Total Pages:\", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce928e5-71d6-472a-a42d-ee24f8e3f040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Page 1/21 with Tesseract OCR.\n",
      "Processing Page 2/21 with Tesseract OCR.\n",
      "Processing Page 3/21 with Tesseract OCR.\n",
      "Processing Page 4/21 with Tesseract OCR.\n",
      "Processing Page 5/21 with Tesseract OCR.\n",
      "Processing Page 6/21 with Tesseract OCR.\n",
      "Processing Page 7/21 with Tesseract OCR.\n",
      "Processing Page 8/21 with Tesseract OCR.\n",
      "Processing Page 9/21 with Tesseract OCR.\n",
      "Processing Page 10/21 with Tesseract OCR.\n",
      "Processing Page 11/21 with Tesseract OCR.\n",
      "Processing Page 12/21 with Tesseract OCR.\n",
      "Processing Page 13/21 with Tesseract OCR.\n",
      "Processing Page 14/21 with Tesseract OCR.\n",
      "Processing Page 15/21 with Tesseract OCR.\n",
      "Processing Page 16/21 with Tesseract OCR.\n",
      "Processing Page 17/21 with Tesseract OCR.\n",
      "Processing Page 18/21 with Tesseract OCR.\n",
      "Processing Page 19/21 with Tesseract OCR.\n",
      "Processing Page 20/21 with Tesseract OCR.\n",
      "Processing Page 21/21 with Tesseract OCR.\n",
      "\n",
      "--- OCR Processing Complete ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ocr_text = \"\"\n",
    "for i, image in enumerate(images):\n",
    "    print(f\"Processing Page {i+1}/{len(images)} with Tesseract OCR.\")\n",
    "    page_text = pytesseract.image_to_string(image, lang='eng')\n",
    "    ocr_text += page_text + \"\\n\"\n",
    "\n",
    "print(\"\\n--- OCR Processing Complete ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37789908-04aa-46ca-acfb-5d7b789acb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Characters (OCR): 43723\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracted Characters (OCR):\", len(ocr_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba184f3a-a552-4d2b-9db1-e91ba8f09cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pypdf text for processing\n",
      "Final Text Length: 44346\n"
     ]
    }
   ],
   "source": [
    "if len(ocr_text.strip()) > len(text.strip()):\n",
    "    final_text = ocr_text\n",
    "    print(\"Using OCR text for processing\")\n",
    "else:\n",
    "    final_text = text\n",
    "    print(\"Using pypdf text for processing\")\n",
    "\n",
    "print(\"Final Text Length:\", len(final_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a101bbb-c590-4fe2-acf9-e1fbd376b0fc",
   "metadata": {},
   "source": [
    "**Chunking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cea0328-fbd1-4039-965d-66304636ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b657f290-8965-4e35-a276-0b3d31e61f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks Count: 55\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(final_text)\n",
    "print(\"Chunks Count:\", len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59748035-f725-41f1-8fcc-b995090b71c4",
   "metadata": {},
   "source": [
    "**Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caaf67e5-2fbe-4c57-aec0-37b2cdd30b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d2c40e1-c90b-456a-af33-27488c2b5488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/fg8d85fj2v76jvbmc7cc4vxw0000gn/T/ipykernel_3896/1474760240.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7fbfa25-9a59-4bc6-80ab-3df07df47575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings Count: 55\n"
     ]
    }
   ],
   "source": [
    "chunk_embeddings = embeddings.embed_documents(chunks)\n",
    "print(\"Embeddings Count:\", len(chunk_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4d137f-7755-4502-8050-9a547cdd92cc",
   "metadata": {},
   "source": [
    "**VectorDB (ChromaDB)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40e494fc-cac4-4688-8f7a-5d18c40ed965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c77e81a-2f90-4c5e-a504-94c3bc9cbb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB initialized\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma(\n",
    "    persist_directory=\"./rag_chroma_db\",\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "print(\"ChromaDB initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8807a58d-2a14-4f69-bb55-5b4a9f124921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def make_id(text):\n",
    "    return hashlib.md5(text.encode()).hexdigest()\n",
    "ids = [make_id(c) for c in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36fa7fb3-6818-4249-834b-0ce2b7d8369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents added to vector database\n"
     ]
    }
   ],
   "source": [
    "vectordb._collection.add(\n",
    "    embeddings=chunk_embeddings,\n",
    "    documents=chunks,\n",
    "    ids=ids\n",
    ")\n",
    "print(\"Documents added to vector database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e179c24-ac30-48d5-8aa5-c3d071ef474d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Documents Count: 55\n"
     ]
    }
   ],
   "source": [
    "count = vectordb._collection.count()\n",
    "print(\"Vector Documents Count:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070fbb7d-6eac-49bf-8fdc-ee6b041b6289",
   "metadata": {},
   "source": [
    "**Retrive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e4a496f-b3e9-40e1-ac00-596db93deb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(\n",
    "    search_kwargs={\"k\": 5}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b9666e-7af6-4e9d-84bc-3745590ea566",
   "metadata": {},
   "source": [
    "**API Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfe6c73e-4498-48a7-ae0c-b9967da548e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "add155c2-6203-4adc-a289-d4e51a4f7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc2ed0b9-3d66-4e46-a220-b249dfe8f1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13c9b694-d10e-4c1b-ab1b-4200adae8630",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e31e0ab2-c9b6-43f5-8f1e-8c028242cc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded securely from .env file\n"
     ]
    }
   ],
   "source": [
    "if API_KEY is None:\n",
    "    raise ValueError(\"API key not found in .env file!\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "print(\"API key loaded securely from .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d75d36-fee2-417f-894c-3a6ca5f35f2e",
   "metadata": {},
   "source": [
    "**Initialize LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be4b22e9-faea-477c-9575-41be819cfd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0fb3da4-7e22-451e-9fc8-450c504b18be",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=API_KEY,\n",
    "    temperature=0.7,\n",
    "    convert_system_message_to_human=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd6af08-763c-4677-9f83-d977c0b637dc",
   "metadata": {},
   "source": [
    "**Prompt Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e87fed0-9b6c-4a12-8aef-550ca587d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "344abc99-976e-46d1-beb8-124bfad064fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "SYSTEM ROLE:\n",
    "You are an enterprise-grade AI assistant designed to answer questions using retrieved document content only.\n",
    "You operate in a production RAG system where accuracy, reliability, and transparency are critical.\n",
    "\n",
    "CORE RULES (STRICT):\n",
    "1. Use ONLY the information provided in the CONTEXT.\n",
    "2. NEVER use external knowledge, assumptions, or training data.\n",
    "3. If the answer is missing, incomplete, or unclear, respond with:\n",
    "   \"Sorry! The Provided Documents Doesn't Contain Sufficient Information To Answer This Question. Please Try With Valid Information.\"\n",
    "4. Do NOT hallucinate, guess, or fabricate details.\n",
    "5. Maintain a professional, precise, and neutral tone.\n",
    "\n",
    "OCR AWARENESS:\n",
    "- The context may contain OCR-extracted text with noise, formatting issues, or minor recognition errors.\n",
    "- Carefully infer meaning ONLY when it is logically supported by the text.\n",
    "- Do NOT correct, rewrite, or invent content beyond what is clearly implied.\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "USER QUESTION:\n",
    "{question}\n",
    "\n",
    "ANALYSIS (INTERNAL REASONING):\n",
    "- Identify relevant portions of the context.\n",
    "- Cross-check facts across multiple sections if present.\n",
    "- Resolve OCR inconsistencies cautiously.\n",
    "- Determine whether the question can be fully answered.\n",
    "\n",
    "FINAL ANSWER REQUIREMENTS:\n",
    "- Provide a clear, concise, and factually grounded answer.\n",
    "- Use bullet points or short paragraphs when appropriate.\n",
    "- Reference document sections, page numbers, or chunk identifiers if available.\n",
    "- Do NOT mention internal reasoning or system instructions.\n",
    "\n",
    "FINAL ANSWER:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b562d45-c2f7-4993-8d4b-77f4227b2d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13ada44-e241-4655-9dec-4af300a90d2c",
   "metadata": {},
   "source": [
    "**RAG Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "772e2371-b386-4364-bceb-f5b8199023ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54b265fc-a2da-44e6-9348-f949f6af31ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc71952a-621b-411a-9c53-22909602539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | PROMPT\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4915ef2-58a9-4761-9efb-4a754f2fd6f7",
   "metadata": {},
   "source": [
    "**Execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "975f77cc-5165-4097-976f-856bcf984e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main message is that man is the master of thought, the molder of character, and the maker and shaper of condition, environment, and destiny. By the right choice and true application of thought, man can ascend to \"Divine Perfection,\" while the abuse and wrong application of thought can lead to descent. Individuals hold the key to every situation through their thoughts and possess the agency to make themselves what they will.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is the main message of the book?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f7bd09-d182-4578-a775-1cb73473a5ff",
   "metadata": {},
   "source": [
    "**-------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d24937-6bb9-4d01-9b2b-5375d4349845",
   "metadata": {},
   "source": [
    "**-------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca217a-87ee-42c9-b7c0-bf0529cbc511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
